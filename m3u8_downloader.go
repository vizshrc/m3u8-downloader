package main

import (
	"bufio"
	"crypto/aes"
	"crypto/cipher"
	"encoding/hex"
	"flag"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

const (
	maxConcurrent = 32 // Concurrent downloads
	maxRetries    = 3  // Retry failed segments
	timeout       = 30 * time.Second
)

type Segment struct {
	Index    int
	URL      string
	Duration float64
	Key      []byte
	IV       []byte
}

type Downloader struct {
	m3u8URL      string
	outputDir    string
	outputFile   string
	client       *http.Client
	segments     []*Segment
	downloadedCh chan *Segment
	errorCh      chan error
	wg           sync.WaitGroup
	progress     int32
	totalSize    int64
}

func NewDownloader(m3u8URL, outputDir, outputFile string) *Downloader {
	return &Downloader{
		m3u8URL:      m3u8URL,
		outputDir:    outputDir,
		outputFile:   outputFile,
		client:       &http.Client{Timeout: timeout},
		segments:     make([]*Segment, 0),
		downloadedCh: make(chan *Segment, maxConcurrent*2),
		errorCh:      make(chan error, 10),
	}
}

// Parse M3U8 file and extract segments
func (d *Downloader) ParseM3U8() error {
	fmt.Println("ğŸ“¥ Fetching m3u8 file...")
	resp, err := d.client.Get(d.m3u8URL)
	if err != nil {
		return fmt.Errorf("failed to fetch m3u8: %w", err)
	}
	defer resp.Body.Close()

	content, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	contentStr := string(content)

	// Check if this is a master playlist (variant streams)
	if strings.Contains(contentStr, "#EXT-X-STREAM-INF") {
		fmt.Println("ğŸ¬ Detected master playlist, fetching best quality variant...")
		variantURL, err := d.extractBestVariant(contentStr)
		if err != nil {
			return err
		}
		fmt.Printf("ğŸ“ Using variant: %s\n", variantURL)
		// Recursively fetch the actual segment playlist
		d.m3u8URL = variantURL
		return d.ParseM3U8()
	}

	baseURL := d.getBaseURL(d.m3u8URL)
	scanner := bufio.NewScanner(strings.NewReader(contentStr))
	var (
		currentKey []byte
		currentIV  []byte
		duration   float64
	)

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())

		if strings.HasPrefix(line, "#EXT-X-KEY:") {
			currentKey, currentIV = d.parseKey(line)
		}

		if strings.HasPrefix(line, "#EXTINF:") {
			parts := strings.Split(line, ",")
			if len(parts) > 0 {
				durationStr := strings.Split(parts[0], ":")[1]
				fmt.Sscanf(strings.TrimSpace(durationStr), "%f", &duration)
			}
		}

		if !strings.HasPrefix(line, "#") && line != "" {
			segmentURL := d.resolveURL(baseURL, line)
			segment := &Segment{
				Index:    len(d.segments),
				URL:      segmentURL,
				Duration: duration,
				Key:      currentKey,
				IV:       currentIV,
			}
			d.segments = append(d.segments, segment)
		}
	}

	fmt.Printf("âœ… Found %d segments\n", len(d.segments))
	return scanner.Err()
}

// Extract best quality variant from master playlist
func (d *Downloader) extractBestVariant(content string) (string, error) {
	lines := strings.Split(content, "\n")
	var bestVariant string
	var maxBandwidth int64 = 0

	for i, line := range lines {
		if strings.Contains(line, "#EXT-X-STREAM-INF") {
			// Extract bandwidth
			bandwidthRegex := regexp.MustCompile(`BANDWIDTH=(\d+)`)
			matches := bandwidthRegex.FindStringSubmatch(line)
			if len(matches) > 1 {
				bandwidth, _ := strconv.ParseInt(matches[1], 10, 64)
				// Get next non-empty line (variant URL)
				if i+1 < len(lines) {
					variant := strings.TrimSpace(lines[i+1])
					if variant != "" && !strings.HasPrefix(variant, "#") {
						if bandwidth > maxBandwidth {
							maxBandwidth = bandwidth
							bestVariant = variant
						}
					}
				}
			}
		}
	}

	if bestVariant == "" {
		return "", fmt.Errorf("no variant found in master playlist")
	}

	baseURL := d.getBaseURL(d.m3u8URL)
	return d.resolveURL(baseURL, bestVariant), nil
}

// Parse encryption key from m3u8
func (d *Downloader) parseKey(line string) ([]byte, []byte) {
	keyRegex := regexp.MustCompile(`URI="([^"]+)"`)
	keyMatch := keyRegex.FindStringSubmatch(line)

	ivRegex := regexp.MustCompile(`IV=0x([0-9a-fA-F]+)`)
	ivMatch := ivRegex.FindStringSubmatch(line)

	var key, iv []byte

	if len(keyMatch) > 1 {
		keyURL := keyMatch[1]
		resp, err := d.client.Get(keyURL)
		if err == nil {
			defer resp.Body.Close()
			key, _ = io.ReadAll(resp.Body)
		}
	}

	if len(ivMatch) > 1 {
		iv, _ = hex.DecodeString(ivMatch[1])
	}

	return key, iv
}

// Get base URL for resolving relative paths
func (d *Downloader) getBaseURL(urlStr string) string {
	u, _ := url.Parse(urlStr)
	pathParts := strings.Split(u.Path, "/")
	basePath := strings.Join(pathParts[:len(pathParts)-1], "/")
	return u.Scheme + "://" + u.Host + basePath + "/"
}

// Resolve relative URLs
func (d *Downloader) resolveURL(baseURL, path string) string {
	if strings.HasPrefix(path, "http://") || strings.HasPrefix(path, "https://") {
		return path
	}
	// If path starts with /, it's absolute path from domain root
	if strings.HasPrefix(path, "/") {
		u, _ := url.Parse(baseURL)
		return u.Scheme + "://" + u.Host + path
	}
	// Otherwise, relative to base URL
	return baseURL + path
}


// Download a single segment with retry logic
func (d *Downloader) downloadSegment(segment *Segment, retries int) error {
	req, _ := http.NewRequest("GET", segment.URL, nil)
	req.Header.Set("User-Agent", "Mozilla/5.0")

	resp, err := d.client.Do(req)
	if err != nil {
		if retries > 0 {
			time.Sleep(time.Duration(maxRetries-retries+1) * time.Second) // Exponential backoff
			return d.downloadSegment(segment, retries-1)
		}
		return fmt.Errorf("failed to download segment %d after %d retries: %w", segment.Index, maxRetries, err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		if retries > 0 {
			time.Sleep(time.Duration(maxRetries-retries+1) * time.Second)
			return d.downloadSegment(segment, retries-1)
		}
		return fmt.Errorf("segment %d returned status %d", segment.Index, resp.StatusCode)
	}

	// Read data
	data, err := io.ReadAll(resp.Body)
	if err != nil {
		if retries > 0 {
			return d.downloadSegment(segment, retries-1)
		}
		return err
	}

	// Decrypt if needed
	if len(segment.Key) > 0 && len(segment.IV) > 0 {
		decrypted, err := d.decryptAES128(data, segment.Key, segment.IV)
		if err != nil {
			return fmt.Errorf("failed to decrypt segment %d: %w", segment.Index, err)
		}
		data = decrypted
	}

	// Save segment
	segmentFile := filepath.Join(d.outputDir, fmt.Sprintf("segment_%06d.ts", segment.Index))
	if err := os.WriteFile(segmentFile, data, 0644); err != nil {
		return err
	}

	atomic.AddInt32(&d.progress, 1)
	current := atomic.LoadInt32(&d.progress)
	percent := (float64(current) / float64(len(d.segments))) * 100
	fmt.Printf("\râ¬‡ï¸  Progress: %d/%d (%.1f%%) ", current, len(d.segments), percent)

	return nil
}

// AES-128 decryption
func (d *Downloader) decryptAES128(ciphertext, key, iv []byte) ([]byte, error) {
	block, err := aes.NewCipher(key)
	if err != nil {
		return nil, err
	}

	mode := cipher.NewCBCDecrypter(block, iv)
	plaintext := make([]byte, len(ciphertext))
	mode.CryptBlocks(plaintext, ciphertext)

	// PKCS7 unpadding
	padLen := int(plaintext[len(plaintext)-1])
	return plaintext[:len(plaintext)-padLen], nil
}

// Download all segments concurrently
func (d *Downloader) DownloadSegments() error {
	fmt.Println("\nğŸš€ Starting concurrent downloads...")
	startTime := time.Now()

	// Create worker pool
	semaphore := make(chan struct{}, maxConcurrent)
	for i := 0; i < maxConcurrent; i++ {
		semaphore <- struct{}{}
	}

	var wg sync.WaitGroup
	errCount := int32(0)

	for _, segment := range d.segments {
		wg.Add(1)
		go func(seg *Segment) {
			defer wg.Done()
			<-semaphore
			defer func() { semaphore <- struct{}{} }()

			if err := d.downloadSegment(seg, maxRetries); err != nil {
				d.errorCh <- err
				atomic.AddInt32(&errCount, 1)
			}
		}(segment)
	}

	wg.Wait()
	close(d.downloadedCh)
	close(d.errorCh)

	if errCount > 0 {
		return fmt.Errorf("encountered %d errors during download", errCount)
	}

	duration := time.Since(startTime)
	fmt.Printf("\nâœ… All segments downloaded in %.2fs\n", duration.Seconds())

	return nil
}

// Merge all segments into output file
func (d *Downloader) MergeSegments() error {
	fmt.Println("ğŸ”— Merging segments...")

	outFile, err := os.Create(d.outputFile)
	if err != nil {
		return err
	}
	defer outFile.Close()

	writer := bufio.NewWriter(outFile)
	defer writer.Flush()

	for i := 0; i < len(d.segments); i++ {
		segmentFile := filepath.Join(d.outputDir, fmt.Sprintf("segment_%06d.ts", i))
		file, err := os.Open(segmentFile)
		if err != nil {
			return fmt.Errorf("failed to open segment %d: %w", i, err)
		}

		if _, err := io.Copy(writer, file); err != nil {
			file.Close()
			return err
		}
		file.Close()

		// Clean up segment file
		os.Remove(segmentFile)
	}

	fmt.Printf("âœ… Merged into: %s\n", d.outputFile)
	return nil
}

// Cleanup temporary directory
func (d *Downloader) Cleanup() {
	os.RemoveAll(d.outputDir)
}

func main() {
	m3u8URL := flag.String("url", "", "M3U8 playlist URL")
	outputFile := flag.String("output", "output.ts", "Output file path")
	workers := flag.Int("workers", maxConcurrent, "Number of concurrent downloads")
	help := flag.Bool("help", false, "Show help")

	flag.Parse()

	if *help || *m3u8URL == "" {
		fmt.Println(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         ğŸ¬ High-Speed M3U8 Video Downloader           â•‘
â•‘                    (Golang Version)                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Usage: m3u8_downloader -url <m3u8_url> [options]

Options:
  -url string
        M3U8 playlist URL (required)
  -output string
        Output file path (default: output.ts)
  -workers int
        Number of concurrent downloads (default: 32)
  -help
        Show this help message

Examples:
  m3u8_downloader -url "https://example.com/video.m3u8"
  m3u8_downloader -url "https://example.com/video.m3u8" -output "video.ts" -workers 64

Why faster than ffmpeg?
  âœ“ Concurrent segment downloads (default: 32 workers)
  âœ“ Efficient memory management
  âœ“ Smart retry logic with exponential backoff
  âœ“ Direct TS merging (no re-encoding)
  âœ“ Optimized for high-bandwidth scenarios

Tips for maximum speed:
  1. Increase workers: -workers 64 (use higher on fast connections)
  2. Convert TS to MP4 after (optional): ffmpeg -i output.ts -c copy output.mp4
  3. Check your internet bandwidth: speedtest.net

		`)
		return
	}

	// Adjust workers
	if *workers > 0 && *workers != maxConcurrent {
		fmt.Printf("âš™ï¸  Using %d concurrent workers\n", *workers)
	}

	// Create temp directory
	tempDir := "./m3u8_temp_" + fmt.Sprintf("%d", time.Now().Unix())
	os.MkdirAll(tempDir, 0755)
	defer os.RemoveAll(tempDir)

	// Initialize downloader
	downloader := NewDownloader(*m3u8URL, tempDir, *outputFile)

	// Parse M3U8
	if err := downloader.ParseM3U8(); err != nil {
		fmt.Printf("âŒ Error parsing M3U8: %v\n", err)
		return
	}

	// Download segments
	if err := downloader.DownloadSegments(); err != nil {
		fmt.Printf("âŒ Error downloading segments: %v\n", err)
		return
	}

	// Merge segments
	if err := downloader.MergeSegments(); err != nil {
		fmt.Printf("âŒ Error merging segments: %v\n", err)
		return
	}

	fmt.Println("\nğŸ‰ Download complete!")
	fmt.Printf("ğŸ“ Output: %s\n", *outputFile)
	fmt.Println("\nğŸ’¡ Next steps:")
	fmt.Println("   Convert to MP4: ffmpeg -i output.ts -c copy output.mp4")
	fmt.Println("   Or play directly: ffplay output.ts")
}
